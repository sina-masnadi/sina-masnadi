<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sina Masnadi</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-174171121-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-174171121-1');
    </script>

</head>

<body id="page-top">

<nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Sina Masnadi</span>
        <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
            <li class="nav-item">
                <a class="nav-link js-scroll-trigger" href="#about">About</a>
            </li>
            <li class="nav-item">
                <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
            </li>
            <li class="nav-item">
                <a class="nav-link js-scroll-trigger" href="#experience">Experience</a>
            </li>
            <li class="nav-item">
                <a class="nav-link js-scroll-trigger" href="resume.pdf">Resume <span class="fas fa-download"></span></a>
            </li>
        </ul>
    </div>
</nav>

<div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
        <div class="w-100">
            <h1 class="mb-0">Sina
                <span class="text-primary">Masnadi</span>
            </h1>
            <div class="subheading mb-5">
                masnadi(at)cs.ucf.edu
            </div>
            <p class="lead mb-5">I am a Computer Science Ph.D. student at University of Central Florida advised by <a
                    href="http://eecs.ucf.edu/~jjl/" target="_blank">Joseph LaViola</a>. As a member of <a
                    href="http://eecs.ucf.edu/isuelab/" target="_blank">ISUE Lab</a>, I am working on Human-Computer
                Iteraction problems. My current project is sketching geometry and physics Informed inference for mobile
                robot manipulation in cluttered scenes.</p>

            <h2 class="mb-3">Education</h2>

            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="resume-content">
                    <h3 class="mb-0">University of Central Florida</h3>
                    <div class="subheading">Ph.D.</div>
                    <div>Computer Science - Human-Robot Interaction</div>
                </div>
                <div class="resume-date text-md-right">
                    <span class="text-primary">August 2015 - Present</span>
                </div>
            </div>

            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="resume-content">
                    <h3 class="mb-0">Sharif University of Technology</h3>
                    <div class="subheading">B.Sc.</div>
                    <div>Computer Science</div>
                </div>
                <div class="resume-date text-md-right">
                    <span class="text-primary">August 2010 - May 2015</span>
                </div>
            </div>

            <div class="social-icons">
                <a href="https://www.linkedin.com/in/sina-masnadi-8761365b/" target="_blank">
                    <i class="fab fa-linkedin-in"></i>
                    <h5>LinkedIn</h5>
                </a>
                <a href="https://github.com/sina-masnadi" target="_blank">
                    <i class="fab fa-github"></i>
                    <h5>GitHub</h5>
                </a>
                <a href="resume.pdf" target="_blank">
                    <i class="fas fa-file"></i>
                    <h5>Resume</h5>
                </a>
                <a href="https://scholar.google.com/citations?user=LOtg1qMAAAAJ&hl=en" target="_blank">
                    <i class="fas fa-graduation-cap"></i>
                    <h5>Scholar</h5>
                </a>
            </div>
        </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="publications">
        <div class="w-100">
            <h2 class="mb-5">Publications</h2>
            <div class="col">
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">Effects of Field of View on Egocentric Distance Perception in Virtual Reality</h3>
                        <div class="subheading">Sina Masnadi, Kevin Pfeil, Jose-Valentin T Sera-Josef, Joseph LaViola</div>
                        <div class="mb-3">CHI Conference on Human Factors in Computing Systems (CHI 2022)
                        </div>
                        <div class="small mb-3">The convex hull problem has practical applications in mesh generation,
                            file searching, cluster analysis, collision detection, image processing, statistics, etc. In
                            this paper, we present a novel pruning-based approach for finding the convex hull set for 2D
                            and 3D datasets using parallel algorithms. This approach, which is a combination of pruning,
                            divide and conquer, and parallel computing, is flexible to be employed in a distributed
                            computing environment.
                            We propose the algorithm for both CPU and GPU (CUDA) computation models. The results show
                            that ConcurrentHull has a performance gain as the input data size increases. Providing an
                            independently dividable approach, our algorithm has the benefit of handling huge datasets as
                            opposed to other approaches presented in this paper which failed to manage the same
                            datasets.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                             <span class="text-primary">
                      <a href="http://www.eecs.ucf.edu/~jjl/pubs/MasnadiVR2020a.pdf">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <div class="embed-responsive embed-responsive-16by9">
                            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/261LDpwV_TY"
                                    frameborder="0"
                                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                                    allowfullscreen></iframe>
                        </div>

                    </div>
                </div>
                <hr/>
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">Distance Perception with a Video See-Through Head-Mounted Display</h3>
                        <div class="subheading">Kevin Pfeil, Sina Masnadi, Jacob Belga, Jose-Valentin T Sera-Josef, Joseph LaViola</div>
                        <div class="mb-3">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI 2021)
                        </div>
                        <div class="small mb-3">In recent years, pass-through cameras have resurfaced as inclusions for virtual reality (VR) hardware. With modern cameras that now have increased resolution and frame rate, Video See-Through (VST) Head-Mounted Displays (HMD) can be used to provide an Augmented Reality (AR) experience. However, because users see their surroundings through video capture and HMD lenses, there is question surrounding how people perceive their environment with these devices. We conducted a user study with 26 participants to help understand if distance perception is altered when viewing surroundings with a VST HMD. Although previous work shows that distance estimation in VR with an HTC Vive is comparable to that in the real world, our results show that the inclusion of a ZED Mini pass-through camera causes a significant difference between normal, unrestricted viewing and that through a VST HMD.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                             <span class="text-primary">
                      <a href="https://www.eecs.ucf.edu/isuelab/publications/pubs/SinaVR2021.pdf">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <a href="http://cs.ucf.edu/~masnadi/img/pub/vr_shell.jpg">
                            <img width="100%"
                                 src="http://cs.ucf.edu/~masnadi/img/pub/vr_shell_s.jpg"
                                 alt="htc vive video pass-through headset using zed mini camera. A VR headset shell to limit user's field of view."/>
                        </a>

                    </div>
                </div>
                <hr/>
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">Field of View Effect on Distance Perception in Virtual Reality</h3>
                        <div class="subheading">Sina Masnadi, Kevin P Pfeil, Jose-Valentin T Sera-Josef, Joseph J LaViola</div>
                        <div class="mb-3">2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
                        </div>
                        <div class="small mb-3">Recent state-of-the-art Virtual Reality (VR) Head-Mounted Displays
                            (HMD) provide wide Field of Views (FoV) which were not possible
                            in the past. Due to this development, HMD FoVs are now approaching a level that parallels natural human eyesight. Previous efforts
                            have shown that reduced FoVs affect user perception of distance in
                            a given environment, but none have investigated VR HMDs with
                            wide FoVs. Therefore, in this paper we directly investigate the effect
                            of HMD FoV on distance estimation in virtual environments. We
                            performed a user study with 14 participants who performed a blind
                            throwing task wearing a Pimax 5K Plus HMD, in which we virtually
                            restricted the FoV to 200°, 110°, and 60°. We found a significant
                            difference in perceived distance between the 200° and 60° FoVs, as well as between the 110°
                            and 60° FoVs. However, no significant difference was observed between 200° and 110°. Our results indicate
                            that users tend to underestimate distance with the narrower FoV
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                             <span class="text-primary">
                      <a href="https://www.eecs.ucf.edu/isuelab/publications/pubs/SinaVR2021.pdf">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <a href="http://cs.ucf.edu/~masnadi/img/pub/ieee_vr_effect_of_field_of_view_on_distance_perecption.jpg">
                            <img width="100%"
                                 src="http://cs.ucf.edu/~masnadi/img/pub/ieee_vr_effect_of_field_of_view_on_distance_perecption.jpg"
                                 alt="Comparison of different FOV in virtual reality environments."/>
                        </a>

                    </div>
                </div>
                <hr/>
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">ConcurrentHull: A Fast Parallel Computing Approach to the Convex Hull
                            Problem</h3>
                        <div class="subheading">Sina Masnadi and Joseph J. LaViola Jr.</div>
                        <div class="mb-3">International Symposium on Visual Computing (ISVC 2019)
                        </div>
                        <div class="small mb-3">The convex hull problem has practical applications in mesh generation,
                            file searching, cluster analysis, collision detection, image processing, statistics, etc. In
                            this paper, we present a novel pruning-based approach for finding the convex hull set for 2D
                            and 3D datasets using parallel algorithms. This approach, which is a combination of pruning,
                            divide and conquer, and parallel computing, is flexible to be employed in a distributed
                            computing environment.
                            We propose the algorithm for both CPU and GPU (CUDA) computation models. The results show
                            that ConcurrentHull has a performance gain as the input data size increases. Providing an
                            independently dividable approach, our algorithm has the benefit of handling huge datasets as
                            opposed to other approaches presented in this paper which failed to manage the same
                            datasets.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                             <span class="text-primary">
                      <a href="http://www.eecs.ucf.edu/~jjl/pubs/MasnadiVR2020a.pdf">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <div class="embed-responsive embed-responsive-16by9">
                            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/iFNUm5rFHaE"
                                    frameborder="0"
                                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                                    allowfullscreen></iframe>
                        </div>

                    </div>
                </div>
                <hr/>
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">Sketching affordances for human-in-the-loop robotic manipulation
                            tasks</h3>
                        <div class="subheading">Sina Masnadi, Joseph J LaViola, Jana Pavlasek, Xiaofan Zhu, Karthik
                            Desingh, O Jenkins
                        </div>
                        <div class="mb-3">ICRA, 2nd Robot Teammates Operating in Dynamic, Unstructured
                            Environments
                            (RT-DUNE)
                        </div>
                        <div class="small mb-3">We propose to enable a human user, without expert knowledge about
                            robotics
                            and
                            programming, to transfer knowledge about affordances in a given scene to a robot. To this
                            end, we propose an
                            easy-to-use system to acquire object geometries and their associated affordances through
                            sketching on a graphical interface. This allows users to interact with robotic systems by
                            utilizing sketch-based techniques to provide a straightforward user interface, as shown in
                            Figure 2. The user sketches the geometry of the object and its affordances. During task
                            execution, when the robot encounters the objects for which it has affordance information, it
                            can
                            execute the affordances by registering the object geometries to its RGB-D data and then
                            performing actions sequentially to achieve the goal.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                             <span class="text-primary">
                      <a href="https://karthikdesingh.com/pdfs/masnadi_et_al_ICRA_2019_WS.pdf">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <a href="http://cs.ucf.edu/~masnadi/img/pub/system_s.jpg">
                            <img width="100%"
                                 src="http://cs.ucf.edu/~masnadi/img/pub/system.jpg"
                                 alt="affordances system"/>
                        </a>
                    </div>
                </div>
                <hr/>
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">VRiAssist: An Eye-Tracked Virtual Reality Low Vision Assistance Tool</h3>
                        <div class="subheading">Sina Masnadi, Brian Williamson, Andrés N Vargas González, Joseph J
                            LaViola
                        </div>
                        <div class="mb-3">IEEE VR, 2020 IEEE Conference on Virtual Reality and 3D User Interfaces
                            Abstracts
                            and Workshops (VRW)
                        </div>
                        <div class="small">We present VRiAssist, an eye-tracking-based visual assistance tool designed
                            to
                            help people with
                            visual impairments interact with virtual reality environments. VRiAssist’s visual
                            enhancements
                            dynamically follow a user’s gaze to project corrections on the affected area of the user’s
                            eyes.
                            VRiAssist provides a distortion correction tool to revert the distortions created by bumps
                            on
                            the retina, a color/brightness correction tool that improves contrast and color perception,
                            and
                            an adjustable magnification tool. The results of a small 5 person user study indicate that
                            VRiAssist helped users see better in the virtual environment depending on their level of
                            visual
                            impairment.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                             <span class="text-primary">
                      <a href="http://www.eecs.ucf.edu/~jjl/pubs/MasnadiVR2020a.pdf">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <div class="embed-responsive embed-responsive-16by9">
                            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/kCp9IZopQq4"
                                    frameborder="0"
                                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                                    allowfullscreen></iframe>
                        </div>

                    </div>
                </div>
                <hr/>
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">AffordIt!: A Tool for Authoring Object Component Behavior in VR</h3>
                        <div class="subheading">Sina Masnadi, Andrés N Vargas González, Brian Williamson, Joseph J
                            LaViola
                        </div>
                        <div class="mb-3">IEEE VR, 2020 IEEE Conference on Virtual Reality and 3D User Interfaces
                            Abstracts
                            and Workshops (VRW)
                        </div>
                        <div class="small">This paper presents AffordIt!, a tool for adding affordances to the component
                            parts of a
                            virtual object. Following 3D scene reconstruction and segmentation procedures, domain
                            experts
                            find themselves with complete virtual objects, but no intrinsic behaviors have been
                            assigned,
                            forcing them to use unfamiliar Desktop-based 3D editing tools. Our solution allows a user to
                            select a region of interest for a mesh cutter tool, assign an intrinsic behavior and view an
                            animation preview of their work. To evaluate the usability and workload of AffordIt! we ran
                            an
                            exploratory study to gather feedback. Results show high usability and low workload ratings.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                       <span class="text-primary">
                      <a href="http://www.eecs.ucf.edu/isuelab/publications/pubs/MasnadiVR2020b.pdf">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <div class="embed-responsive embed-responsive-16by9">
                            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/xgwNmD_PovU"
                                    frameborder="0"
                                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                                    allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
                <hr/>
                <div class="mb-12 row">
                    <div class="p-0 col-xl-9 col-sm-12">
                        <h3 class="mb-0">A Sketch-Based System for Human-Guided Constrained Object Manipulation</h3>
                        <div class="subheading">Sina Masnadi, Joseph J. LaViola Jr., Xiaofan Zhu, Karthik Desingh,
                            Odest Chadwicke Jenkins
                        </div>
                        <div class="mb-3">arXiv preprint arXiv:1911.07340</div>
                        <div class="small">In this paper, we present an easy to use sketch-based interface to extract
                            geometries and
                            generate affordance files from 3D point clouds for robot-object interaction tasks. Using our
                            system, even novice users can perform robot task planning by employing such sketch tools.
                            Our
                            focus in this paper is employing human-in-the-loop approach to assist in the generation of
                            more
                            accurate affordance templates and guidance of robot through the task execution process.
                            Since we
                            do not employ any unsupervised learning to generate affordance templates, our system
                            performs
                            much faster and is more versatile for template generation. Our system is based on the
                            extraction
                            of geometries for generalized cylindrical and cuboid shapes, after extracting the
                            geometries,
                            affordances are generated for objects by applying simple sketches. We evaluated our
                            technique by
                            asking users to define affordances by employing sketches on the 3D scenes of a door handle
                            and a
                            drawer handle and used the resulting extracted affordance template files to perform the
                            tasks of
                            turning a door handle and opening a drawer by the robot.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                      <span class="text-primary">
                      <a href="https://arxiv.org/pdf/1911.07340">
                        PDF <span class="fas fa-download"></span></a></span>
                        <br/>
                        <br/>
                        <a href="http://cs.ucf.edu/~masnadi/img/pub/dh.png">
                            <img width="100%" src="http://cs.ucf.edu/~masnadi/img/pub/dh.png" alt="door handle"/>
                        </a>
                    </div>
                </div>
                <hr/>
                <div class="mb-3 row">
                    <div class="p-0 col-xl-12 col-sm-12">
                        <h3 class="mb-0">Investigating the Value of Privacy within the Internet of Things</h3>
                        <div class="subheading">Alex Mayle, Neda Hajiakhoond Bidoki, Sina Masnadi, Ladislau Boeloeni,
                            Damla Turgut
                        </div>
                        <div class="mb-3">GLOBECOM 2017-2017 IEEE Global Communications Conference, 1-6</div>
                        <div class="small">Many companies within the Internet of Things (IoT) sector rely on the
                            personal
                            data of users to
                            deliver and monetize their services, creating a high demand for personal information. A user
                            can
                            be seen as making a series of transactions, each involving the exchange of personal data for
                            a
                            service. In this paper, we argue that privacy can be described quantitatively, using the
                            game-
                            theoretic concept of value of information (VoI), enabling us to assess whether each exchange
                            is
                            an advantageous one for the user. We introduce PrivacyGate, an extension to the Android
                            operating system built for the purpose of studying privacy of IoT transactions. An example
                            study, and its initial results, are provided to illustrate its capabilities.
                        </div>
                    </div>
                    <div class="col-xl-12 col-sm-12">
                       <span class="text-primary"><a
                               href="http://www.eecs.ucf.edu/~turgut/Research/Publications/Download/Mayle-2017-GLOBECOM.pdf">
                        PDF <span class="fas fa-download"/></a></span>
                        <br/>
                        <br/>
                        <a href="http://cs.ucf.edu/~masnadi/img/pub/prv.jpg">
                            <img width="100%" src="http://cs.ucf.edu/~masnadi/img/pub/prv.jpg" alt="door handle"/>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="experience">
        <div class="w-100">
            <h2 class="mb-5">Experience</h2>
            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="resume-content">
                    <h3 class="mb-0">Research Scienctist</h3>
                    <div class="subheading mb-3"><a href="https://ximpatico.com/">Ximpatico</a></div>
                    <p>Developed robotic systems for household and industrial applications using state-of-the-art machine learning and artificial intelligence approaches.</p>
                </div>
                <div class="resume-date text-md-right">
                    <span class="text-primary">Jan 2021 - Present</span>
                </div>
            </div>

            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="resume-content">
                    <h3 class="mb-0">Full-stack Developer</h3>
                    <div class="subheading mb-3"><a href="https://www.careerfairplus.com/">Career Fair Plus</a></div>
                    <p>Developed web-services using Node.js, MongoDB, Heroku, AWS, and Angular JS. Among my
                        responsibilities, I was in charge of transforming the traditional servers to cloud services
                        using Node.js and AWS (Lambda, S3, and EC2). I also helped with Android app development by
                        integrating Google Firebase services for user profile management.</p>
                </div>
                <div class="resume-date text-md-right">
                    <span class="text-primary">Jun 2016 - Aug 2017</span>
                </div>
            </div>

            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="resume-content">
                    <h3 class="mb-0">Android Developer</h3>
                    <div class="subheading mb-3"><a
                            href="https://www.linkedin.com/company/iranian-congenial-mobile-co.">Cafe Bazaar</a></div>
                    <p>Cafe Bazaar is the largest private mobile software company in Iran. I worked on its main product,
                        called "Bazaar", which is an Android application marketplace (similar to Google Play) for
                        Iranian smartphone users. Currently, it has more than 36 million active users. Some of my
                        collaborations in this company are as follows:
                    <ul>
                        <li>UI/UX design based on persona, scenario, and goal</li>
                        <li>Improving UX using user study, A/B testing and data analytics</li>
                        <li>Creating an Android image caching system (this happened before Fresco, UIL, Picasso, and
                            other libraries become popular)
                        </li>
                        <li>Implementing root installation for apps. Automatic update of installed apps which mimics
                            Google Play and App Store
                        </li>
                        <li>Design and implement server/client data transfer protocols and structures</li>
                        <li>Collaborating in implementing apk delta update (Update Android apps by their diff)</li>
                    </ul>
                    </p>
                </div>
                <div class="resume-date text-md-right">
                    <span class="text-primary">Dec 2012 - Aug 2015</span>
                </div>
            </div>

            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="resume-content">
                    <h3 class="mb-0">Co-Founder & CTO</h3>
                    <div class="subheading mb-3"><a href="http://cafebazaar.ir/app/sina.apps.ghabzak/?l=en">Ghabzak</a>
                    </div>
                    <p>An Android application for paying and managing bills.
                    </p>
                </div>
                <div class="resume-date text-md-right">
                    <span class="text-primary">2013 - 2018</span>
                </div>
            </div>

            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="resume-content">
                    <h3 class="mb-0">Creator</h3>
                    <div class="subheading mb-3"><a
                            href="http://cafebazaar.ir/app/sina.apps.ghabzak/?l=en">WallpaperHaa</a></div>
                    <p>An Android wallpaper application with more than 300,000 active users at its peak.
                    </p>
                </div>
                <div class="resume-date text-md-right">
                    <span class="text-primary">2013 - 2017</span>
                </div>
            </div>

        </div>

    </section>

</div>

<!-- Bootstrap core JavaScript -->
<script src="vendor/jquery/jquery.min.js"></script>
<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

<!-- Plugin JavaScript -->
<script src="vendor/jquery-easing/jquery.easing.min.js"></script>

<!-- Custom scripts for this template -->
<script src="js/resume.min.js"></script>

</body>

</html>
